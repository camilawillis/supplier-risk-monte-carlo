# -*- coding: utf-8 -*-
"""ANÁLISIS_DE_PROVEEDORES_MONTE_CARLO_ESTACIONAL.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19IIC4tFKepdltbZie1m0YpS9ZOiIK4TW

# **ANÁLISIS DE CAPACIDADES DE PROVEEDORES y MONTE CARLO ESTACIONAL**

## ARQUITECTURA:
##   - Datos: 2023-2025 filtrados (Nacional, bota, todas tallas/sucursales)
##   - Enfoque: Monte Carlo estacional mes a mes
##   - Output: predicción de demanda, prob. desabasto y SS para cada mes de 2026

## LIBRERÍAS
"""

import pandas as pd
import numpy as np
from scipy import stats
from scipy.stats import spearmanr
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

"""## 0. CONFIGURACIÓN GLOBAL"""

ARCHIVO_CSV    = "/content/BD_PROYECTO_RETO.csv"
N_SIMULACIONES = 10_000
NIVEL_SERVICIO = 0.95
FACTOR_NEGADOS = 0.25

# Solo los meses con 3 años completos de historia y demanda real significativa
MESES_VALIDOS  = [7, 8, 9, 10, 11, 12]
MESES_NOMBRE   = {7:'Jul', 8:'Ago', 9:'Sep', 10:'Oct', 11:'Nov', 12:'Dic'}
AÑO_PREDICCION = 2026

# Cap de exceso: máximo N veces la media histórica mensual del proveedor
CAP_EXCESO_MULT = 5.0

"""## 1. CARGA Y LIMPIEZA DE DATOS"""

def cargar_datos(path):
    print("Iniciando ingesta de datos...")
    df = pd.read_csv(path, sep=None, engine='python')
    df.columns = df.columns.str.strip().str.upper()
    df.rename(columns={'PROVEDOR': 'PROVEEDOR'}, inplace=True)

    df['MES']      = df['MES'].astype(int)
    df['AÑO']      = df['AÑO'].astype(int)
    df['VENTAS']   = pd.to_numeric(df['VENTAS'],  errors='coerce').fillna(0)
    df['NEGADOS']  = pd.to_numeric(df['NEGADOS'], errors='coerce').fillna(0)

    df['NEGADOS_AJUSTADOS'] = df['NEGADOS'] * FACTOR_NEGADOS
    df['DEMANDA_REAL']      = df['VENTAS'] + df['NEGADOS_AJUSTADOS']

    df['FECHA'] = pd.to_datetime(
        df['AÑO'].astype(str) + '-' + df['MES'].astype(str).str.zfill(2) + '-01'
    )

    df = df[df['MES'].isin(MESES_VALIDOS)].copy()

    print(f"[OK] Datos cargados: {df.shape[0]:,} registros válidos.\n")
    return df

"""## 2. MÉTRICAS HISTÓRICAS POR PROVEEDOR"""

def calcular_metricas(df, alpha=1.0):
    g = df.groupby('PROVEEDOR').agg(
        VENTAS_TOTAL      = ('VENTAS',            'sum'),
        NEGADOS_TOTAL_RAW = ('NEGADOS',           'sum'),
        NEGADOS_AJUST     = ('NEGADOS_AJUSTADOS', 'sum'),
        DEMANDA_TOTAL     = ('DEMANDA_REAL',      'sum'),
        DEMANDA_MEDIA     = ('DEMANDA_REAL',      'mean'),
        DEMANDA_STD       = ('DEMANDA_REAL',      'std'),
    ).reset_index()

    g['FULFILLMENT_RATE'] = (g['VENTAS_TOTAL'] / g['DEMANDA_TOTAL'].replace(0, np.nan)).fillna(1)
    g['TASA_NEGADOS'] = 1 - g['FULFILLMENT_RATE']

    cv_col = (g['DEMANDA_STD'] / g['DEMANDA_MEDIA'].replace(0, np.nan)).fillna(0)
    g['SCORE_RIESGO'] = alpha * g['TASA_NEGADOS'] + (1 - alpha) * cv_col

    p33 = g['SCORE_RIESGO'].quantile(0.33)
    p66 = g['SCORE_RIESGO'].quantile(0.66)
    g['NIVEL_RIESGO'] = pd.cut(
        g['SCORE_RIESGO'],
        bins=[-np.inf, p33, p66, np.inf],
        labels=['BAJO', 'MEDIO', 'ALTO']
    )
    return g.sort_values('SCORE_RIESGO', ascending=False).reset_index(drop=True)

"""## 3. CROSS-VALIDATION WALK-FORWARD"""

def cross_validate_pesos(df, n_splits=3, paso=0.05):
    alphas    = np.arange(0, 1 + paso, paso).round(2)
    fechas    = sorted(df['FECHA'].unique())
    fold_size = len(fechas) // n_splits
    resultados = []

    for alpha in alphas:
        correlaciones = []
        for fold in range(1, n_splits):
            corte    = fechas[fold * fold_size]
            df_train = df[df['FECHA'] <  corte]
            df_val   = df[df['FECHA'] >= corte]
            if df_train.empty or df_val.empty:
                continue

            g_train = df_train.groupby('PROVEEDOR').agg(
                VENTAS_TOTAL  = ('VENTAS',       'sum'),
                DEMANDA_TOTAL = ('DEMANDA_REAL', 'sum'),
                DEMANDA_MEDIA = ('DEMANDA_REAL', 'mean'),
                DEMANDA_STD   = ('DEMANDA_REAL', 'std'),
            ).reset_index()
            g_train['TASA']  = 1 - (g_train['VENTAS_TOTAL'] / g_train['DEMANDA_TOTAL'].replace(0, np.nan)).fillna(1)
            g_train['CV']    = (g_train['DEMANDA_STD'] / g_train['DEMANDA_MEDIA'].replace(0, np.nan)).fillna(0)
            g_train['SCORE'] = alpha * g_train['TASA'] + (1 - alpha) * g_train['CV']

            g_val = df_val.groupby(['PROVEEDOR', 'FECHA']).agg(
                VENTAS_M  = ('VENTAS',       'sum'),
                DEMANDA_M = ('DEMANDA_REAL', 'sum'),
            ).reset_index()
            g_val['TASA_NEG_M'] = 1 - (g_val['VENTAS_M'] / g_val['DEMANDA_M'].replace(0, np.nan)).fillna(1)
            g_val_agg = g_val.groupby('PROVEEDOR')['TASA_NEG_M'].mean().reset_index()
            g_val_agg.columns = ['PROVEEDOR', 'TASA_NEG_FUTURA']

            merged = g_train[['PROVEEDOR', 'SCORE']].merge(g_val_agg, on='PROVEEDOR')
            if len(merged) < 3:
                continue
            rho, _ = spearmanr(merged['SCORE'], merged['TASA_NEG_FUTURA'])
            if not np.isnan(rho):
                correlaciones.append(rho)

        if correlaciones:
            resultados.append({
                'alpha'    : alpha,
                'rho_media': np.mean(correlaciones),
                'rho_std'  : np.std(correlaciones),
            })

    return pd.DataFrame(resultados)

def run_cross_validation(df):
    print("Validando modelo (Cross-Validation Walk-Forward)...")
    cv_res    = cross_validate_pesos(df)
    mejor     = cv_res.loc[cv_res['rho_media'].idxmax()]
    alpha_opt = mejor['alpha']
    print(f"[OK] Parámetro óptimo encontrado: alpha={alpha_opt}\n")

    fig, ax = plt.subplots(figsize=(10, 4))
    ax.plot(cv_res['alpha'], cv_res['rho_media'], color='steelblue', linewidth=2.5)
    ax.fill_between(cv_res['alpha'],
                    cv_res['rho_media'] - cv_res['rho_std'],
                    cv_res['rho_media'] + cv_res['rho_std'],
                    alpha=0.2, color='steelblue', label='+-1 Desv. Est.')
    ax.axvline(alpha_opt, color='#e74c3c', linestyle='--', linewidth=2,
               label=f'alpha optimo={alpha_opt}  rho={mejor["rho_media"]:.3f}')
    ax.set_xlabel('alpha (peso TASA_NEGADOS)')
    ax.set_ylabel('Correlación de Spearman')
    ax.set_title('Optimización de Hiperparámetro de Riesgo', fontweight='bold')
    ax.legend(); ax.grid(alpha=0.3)
    plt.tight_layout()
    plt.savefig('06_cross_validation_pesos.png', dpi=150)
    plt.close(fig)
    return alpha_opt

"""## 4. AJUSTE DE DISTRIBUCIÓN POR PROVEEDOR (AIC)"""

def ajustar_distribucion(serie):
    data = serie.dropna().values
    data = data[data > 0]
    if len(data) < 2:
        mu = float(np.mean(data)) if len(data) > 0 else 1.0
        return 'norm', (mu, max(mu * 0.1, 0.1))

    candidatos = {'norm': stats.norm.fit(data), 'gamma': stats.gamma.fit(data, floc=0)}
    mejor, mejor_aic = None, np.inf
    for nombre, params in candidatos.items():
        try:
            log_l = getattr(stats, nombre).logpdf(data, *params).sum()
            aic   = 2 * len(params) - 2 * log_l
            if aic < mejor_aic:
                mejor_aic = aic
                mejor = (nombre, params)
        except Exception:
            pass
    return mejor if mejor else ('norm', (float(np.mean(data)), max(float(np.std(data)), 0.1)))

"""## 5. SIMULACIÓN MONTE CARLO ESTACIONAL — SOLO JUL-DIC"""

def simular_proveedor_estacional(df, proveedor, n_sim=N_SIMULACIONES):
    rng = np.random.default_rng(42)
    datos_prov = df[df['PROVEEDOR'] == proveedor].copy()
    resultados_mensuales = []

    for mes in MESES_VALIDOS:
        datos_mes = datos_prov[datos_prov['MES'] == mes]
        serie_dem = datos_mes.groupby('AÑO')['DEMANDA_REAL'].sum()

        sin_neg   = datos_mes[datos_mes['NEGADOS'] == 0]
        serie_cap = sin_neg.groupby('AÑO')['VENTAS'].sum()

        if len(serie_cap) < 2:
            serie_cap = datos_mes.groupby('AÑO')['VENTAS'].sum() * 1.05

        d_nom, d_par = ajustar_distribucion(serie_dem)
        c_nom, c_par = ajustar_distribucion(serie_cap)
        dist_d = getattr(stats, d_nom)
        dist_c = getattr(stats, c_nom)

        dem_sim = np.maximum(0, dist_d.rvs(*d_par, size=n_sim, random_state=rng))
        cap_sim = np.maximum(0, dist_c.rvs(*c_par, size=n_sim, random_state=rng))
        exceso  = np.maximum(0, dem_sim - cap_sim)

        media_hist = float(serie_dem.mean()) if len(serie_dem) > 0 else 1.0
        cap_valor  = media_hist * CAP_EXCESO_MULT
        exceso     = np.minimum(exceso, cap_valor)

        if len(serie_dem) >= 2:
            años = serie_dem.index.values.astype(float)
            tendencia_cruda = float(np.polyfit(años, serie_dem.values, 1)[0])
            max_tendencia = media_hist * 0.20
            tendencia = np.clip(tendencia_cruda, -max_tendencia, max_tendencia)
        else:
            tendencia = 0.0

        resultados_mensuales.append({
            'proveedor'        : proveedor,
            'mes'              : mes,
            'mes_nombre'       : MESES_NOMBRE[mes],
            'n_obs'            : int(len(serie_dem)),
            'demanda_esperada' : float(dem_sim.mean()),
            'demanda_p05'      : float(np.percentile(dem_sim, 5)),
            'demanda_p95'      : float(np.percentile(dem_sim, 95)),
            'prob_desabasto'   : float((exceso > 0).mean()),
            'exceso_medio'     : float(exceso.mean()),
            'stock_seguridad'  : float(np.percentile(exceso, NIVEL_SERVICIO * 100)),
            'tendencia_anual'  : tendencia,
            'dist_demanda'     : d_nom,
            'demanda_media_hist': float(serie_dem.mean()),
            'exceso_sim'       : exceso # Guardado oculto para el simulador estratégico
        })

    return resultados_mensuales

def simular_transferencia_volumen(res_mensuales_prim, df, proveedor_estrella, n_sim=N_SIMULACIONES):
    rng = np.random.default_rng(123)
    datos_resp = df[df['PROVEEDOR'] == proveedor_estrella]
    resultados = []

    for r in res_mensuales_prim:
        mes = r['mes']
        datos_mes_resp = datos_resp[datos_resp['MES'] == mes]
        sin_neg_resp   = datos_mes_resp[datos_mes_resp['NEGADOS'] == 0]
        serie_cap_resp = sin_neg_resp.groupby('AÑO')['VENTAS'].sum()

        if len(serie_cap_resp) < 2:
            serie_cap_resp = datos_mes_resp.groupby('AÑO')['VENTAS'].sum() * 1.05

        c_nom, c_par = ajustar_distribucion(serie_cap_resp)
        cap_resp     = np.maximum(0, getattr(stats, c_nom).rvs(*c_par, size=n_sim, random_state=rng))

        exceso_nuevo = np.maximum(0, r['exceso_sim'] - cap_resp)
        cap_valor    = r['demanda_media_hist'] * CAP_EXCESO_MULT
        exceso_nuevo = np.minimum(exceso_nuevo, cap_valor)

        reduccion = 1 - (exceso_nuevo > 0).mean() / max(r['prob_desabasto'], 1e-9)

        resultados.append({
            'mes'                 : mes,
            'mes_nombre'          : r['mes_nombre'],
            'prob_desabasto_nuevo': float((exceso_nuevo > 0).mean()),
            'ss_nuevo'            : float(np.percentile(exceso_nuevo, NIVEL_SERVICIO * 100)),
            'reduccion_riesgo_%'  : float(reduccion * 100),
            'ahorro_unidades'     : float(r['exceso_medio'] - exceso_nuevo.mean()),
        })
    return resultados

"""## 6. VISUALIZACIONES"""

def plot_fulfillment(metricas):
    fig, ax = plt.subplots(figsize=(12, 8))
    colores = metricas['NIVEL_RIESGO'].map({'BAJO': '#2ecc71', 'MEDIO': '#f39c12', 'ALTO': '#e74c3c'})
    bars = ax.barh(metricas['PROVEEDOR'], metricas['FULFILLMENT_RATE'] * 100, color=colores, edgecolor='white')
    ax.axvline(95, color='gray', linestyle='--', linewidth=1.5, label='Meta 95%')
    ax.set_xlabel('Fulfillment Rate (%)')
    ax.set_title('Radiografía Histórica de Cumplimiento', fontweight='bold')
    ax.set_xlim(0, 108); ax.legend()
    for bar, val in zip(bars, metricas['FULFILLMENT_RATE'] * 100):
        ax.text(val + 0.3, bar.get_y() + bar.get_height() / 2, f'{val:.1f}%', va='center', fontsize=7)
    plt.tight_layout()
    plt.savefig('01_fulfillment_proveedores.png', dpi=150)
    plt.show() # Mostrar 1 vez

def plot_prediccion_2026(proveedor, res_mensuales):
    meses    = [r['mes_nombre'] for r in res_mensuales]
    dem_med  = [r['demanda_esperada'] for r in res_mensuales]
    dem_p05  = [r['demanda_p05'] for r in res_mensuales]
    dem_p95  = [r['demanda_p95'] for r in res_mensuales]
    prob_des = [r['prob_desabasto'] * 100 for r in res_mensuales]
    ss       = [r['stock_seguridad'] for r in res_mensuales]
    dem_hist = [r['demanda_media_hist'] for r in res_mensuales]

    fig = plt.figure(figsize=(14, 10))
    gs  = gridspec.GridSpec(3, 1, hspace=0.5)
    x   = np.arange(len(meses))

    ax1 = fig.add_subplot(gs[0])
    ax1.fill_between(x, dem_p05, dem_p95, alpha=0.25, color='steelblue', label='Intervalo P5-P95')
    ax1.plot(x, dem_med, 'o-', color='steelblue', linewidth=2, label='Demanda esperada 2026')
    ax1.plot(x, dem_hist, 's--', color='gray', linewidth=1.5, label='Promedio histórico')
    ax1.set_xticks(x); ax1.set_xticklabels(meses); ax1.set_ylabel('Unidades')
    ax1.set_title(f'Predicción de Demanda Estocástica - {proveedor}', fontweight='bold')
    ax1.legend(fontsize=8); ax1.grid(alpha=0.3)

    ax2 = fig.add_subplot(gs[1])
    colores_bar = ['#e74c3c' if p > 60 else '#f39c12' if p > 40 else '#2ecc71' for p in prob_des]
    ax2.bar(x, prob_des, color=colores_bar, edgecolor='white', alpha=0.85)
    ax2.axhline(50, color='gray', linestyle='--', linewidth=1, alpha=0.7)
    ax2.set_xticks(x); ax2.set_xticklabels(meses); ax2.set_ylabel('Probabilidad (%)'); ax2.set_ylim(0, 105)
    ax2.set_title('Riesgo de Desabasto por Mes', fontweight='bold'); ax2.grid(alpha=0.3, axis='y')

    ax3 = fig.add_subplot(gs[2])
    ax3.bar(x, ss, color='#3498db', edgecolor='white', alpha=0.85)
    ax3.set_xticks(x); ax3.set_xticklabels(meses); ax3.set_ylabel('Unidades')
    ax3.set_title('Stock de Seguridad Sugerido (P95)', fontweight='bold'); ax3.grid(alpha=0.3, axis='y')

    plt.tight_layout()
    plt.savefig(f'03_prediccion_2026_{proveedor}.png', dpi=150, bbox_inches='tight')
    plt.close(fig) # IMPORTANTE: Cierra la figura silenciosamente para no pausar el loop

def plot_heatmaps_y_resumen(todos_resultados, metricas):
    proveedores = sorted(todos_resultados.keys())

    # Heatmap Probabilidad
    data_p = [[r['prob_desabasto'] * 100 for r in todos_resultados[p]] for p in proveedores]
    df_p = pd.DataFrame(data_p, index=proveedores, columns=[MESES_NOMBRE[m] for m in MESES_VALIDOS])
    fig, ax = plt.subplots(figsize=(10, max(6, len(proveedores) * 0.4)))
    sns.heatmap(df_p, annot=True, fmt='.0f', cmap='RdYlGn_r', ax=ax, linewidths=0.3, cbar_kws={'label': 'Prob. Desabasto (%)'})
    ax.set_title('Matriz de Riesgo de Desabasto 2026', fontweight='bold')
    plt.tight_layout(); plt.savefig('04_heatmap_prob_desabasto.png', dpi=150); plt.show()

    # Heatmap Stock Seguridad
    data_s = [[r['stock_seguridad'] for r in todos_resultados[p]] for p in proveedores]
    df_s = pd.DataFrame(data_s, index=proveedores, columns=[MESES_NOMBRE[m] for m in MESES_VALIDOS])
    fig, ax = plt.subplots(figsize=(10, max(6, len(proveedores) * 0.4)))
    sns.heatmap(df_s, annot=True, fmt='.0f', cmap='Blues', ax=ax, linewidths=0.3, cbar_kws={'label': 'Unidades SS'})
    ax.set_title('Matriz de Inventario de Seguridad 2026', fontweight='bold')
    plt.tight_layout(); plt.savefig('05_heatmap_stock_seguridad.png', dpi=150); plt.show()

"""## 7. EXPORTACIÓN DE TABLAS"""

def generar_tablas(metricas, todos_resultados, todos_transferencia):
    # Tabla Riesgo
    t_riesgo = metricas.copy()
    t_riesgo['SCORE_RIESGO'] = t_riesgo['SCORE_RIESGO'].round(4)
    t_riesgo.to_csv('tabla_riesgo_proveedores.csv', index=False)

    # Tabla Predicción
    rows_p = []
    for prov, res_list in todos_resultados.items():
        for r in res_list:
            rows_p.append({
                'PROVEEDOR': prov, 'MES': r['mes'], 'MES_NOMBRE': r['mes_nombre'],
                'DEMANDA_ESPERADA': round(r['demanda_esperada'], 0),
                'PROB_DESABASTO': f"{r['prob_desabasto']*100:.1f}%",
                'STOCK_SEG_REC': round(r['stock_seguridad'], 0),
                'DIST_DEMANDA': r['dist_demanda']
            })
    pd.DataFrame(rows_p).to_csv('tabla_prediccion_2026.csv', index=False)

    # Tabla Estrategia Multiproveedor
    rows_t = []
    for prov_malo, transferencias_por_bueno in todos_transferencia.items():
        for prov_bueno, res_list in transferencias_por_bueno.items():
            for i, r in enumerate(res_list):
                rows_t.append({
                    'PROV_RIESGO': prov_malo,
                    'PROV_A_DESARROLLAR': prov_bueno,
                    'MES': r['mes'],
                    'MES_NOMBRE': r['mes_nombre'],
                    'PROB_ACTUAL': f"{todos_resultados[prov_malo][i]['prob_desabasto']*100:.1f}%",
                    'PROB_TRANSFERIDA': f"{r['prob_desabasto_nuevo']*100:.1f}%",
                    'VOLUMEN_SALVADO': round(r['ahorro_unidades'], 0)
                })
    pd.DataFrame(rows_t).to_csv('tabla_transferencia_estrategica.csv', index=False)

def analizar_interseccion_modelos(df, proveedor_estrella):
    modelos_estrella = set(df[df['PROVEEDOR'] == proveedor_estrella]['MODELO'].unique())
    intersecciones = [prov for prov in df['PROVEEDOR'].unique()
                      if prov != proveedor_estrella and
                      len(modelos_estrella.intersection(set(df[df['PROVEEDOR'] == prov]['MODELO'].unique()))) > 0]

    print(f"  [{proveedor_estrella}] fabrica {len(modelos_estrella)} modelo(s). Comparte SKUs con el resto: {'Sí' if intersecciones else 'No'}")

"""## 8. MAIN ENGINE"""

def main():
    print("=" * 60)
    print(" PIPELINE ANALÍTICO DE RIESGO DE PROVEEDORES")
    print("=" * 60 + "\n")

    df = cargar_datos(ARCHIVO_CSV)
    alpha_opt = run_cross_validation(df)

    metricas = calcular_metricas(df, alpha=alpha_opt)
    plot_fulfillment(metricas)

    proveedores = df['PROVEEDOR'].unique()
    todos_resultados = {}

    print(f"\nGenerando Simulaciones Monte Carlo (10,000 iteraciones/mes)...")
    for i, prov in enumerate(proveedores, 1):
        print(f"  [{i}/{len(proveedores)}] Procesando {prov}...", end="\r")
        res = simular_proveedor_estacional(df, prov)
        todos_resultados[prov] = res
        plot_prediccion_2026(prov, res) # Generación silenciosa
    print(f"\n[OK] 100% Simulaciones completadas exitosamente.")

    # --- POOL DE PROVEEDORES ---
    # Top 3 Mejores Proveedores (Riesgo BAJO, Tasa de cumplimiento alta)
    mejores_proveedores = metricas.tail(3)['PROVEEDOR'].tolist()

    # Proveedores Críticos a rescatar (Riesgo ALTO)
    proveedores_alto_riesgo = metricas[metricas['NIVEL_RIESGO'] == 'ALTO']['PROVEEDOR'].tolist()

    print("\n[ANÁLISIS DE COMPLEJIDAD] Evaluando el Top 3 de Proveedores Estrella:")
    for prov in mejores_proveedores:
        analizar_interseccion_modelos(df, prov)

    todos_transferencia = {}
    for prov_malo in proveedores_alto_riesgo:
        todos_transferencia[prov_malo] = {}
        for prov_bueno in mejores_proveedores:
            todos_transferencia[prov_malo][prov_bueno] = simular_transferencia_volumen(
                todos_resultados[prov_malo], df, prov_bueno
            )

    print("\nGenerando Heatmaps y consolidando reportes CSV...")
    plot_heatmaps_y_resumen(todos_resultados, metricas)
    generar_tablas(metricas, todos_resultados, todos_transferencia)

    print("\n" + "=" * 60)
    print(" PIPELINE FINALIZADO. ENTREGABLES GUARDADOS:")
    print("  - tabla_riesgo_proveedores.csv")
    print("  - tabla_prediccion_2026.csv")
    print("  - tabla_transferencia_estrategica.csv")
    print("  - 45+ Gráficos PNG en directorio raíz.")
    print("=" * 60)

if __name__ == "__main__":
    main()